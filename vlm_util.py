import json
import time
from mlx_vlm import load, generate
from mlx_vlm.prompt_utils import apply_chat_template
from mlx_vlm.utils import load_config

class VLMProcessor:
    def __init__(self):
        self.vl_model, self.vl_processor = load("mlx-community/Qwen3-VL-8B-Instruct-8bit")
        self.vl_config = load_config("mlx-community/Qwen3-VL-8B-Instruct-8bit")

    def read_message(self,frame):
        print(f"ğŸ“… VLè¯†åˆ«å¯¹æ–¹æ¶ˆæ¯å¼€å§‹ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}")
        image = [frame]
        prompt = "ç»™å‡ºå¾®ä¿¡èŠå¤©æ¡†ä¸­å¯¹æ–¹å‘é€çš„æœ€æ–°ä¸€æ¡æ¶ˆæ¯ï¼Œæ³¨æ„åœ¨ç•Œé¢ä¸­è¶Šé ä¸‹è¶Šæ–°ï¼Œé å·¦ä¾§çš„ç™½è‰²èŠå¤©æ¡†æ˜¯å¯¹æ–¹å‘é€çš„æ¶ˆæ¯ï¼Œè¿”å›JSONï¼Œå‚æ•°ï¼šmsg(æ¶ˆæ¯å†…å®¹)ï¼Œåªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—å†…å®¹ï¼Œå¦‚æœè§£æå¤±è´¥æˆ–è€…å¯¹æ–¹æ²¡æœ‰å‘é€ï¼Œmsgä¸ºç©º"

        # Apply chat template
        formatted_prompt = apply_chat_template(
            self.vl_processor, self.vl_config, prompt, num_images=1
        )

        output = generate(self.vl_model, self.vl_processor, formatted_prompt, image)
        result = output.text
        print(f"VLè¯†åˆ«å¯¹æ–¹æ¶ˆæ¯ç»“æœï¼š{result}")
        print(f"ğŸ“… VLè¯†åˆ«å¯¹æ–¹æ¶ˆæ¯ç»“æŸï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}")
        result_json = json.loads(result)
        if result_json["msg"]:
            return result_json["msg"]
        else:
            raise Exception("message is none")